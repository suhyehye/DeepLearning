{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-1. 4차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.rand(10, 1, 28, 28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "높이 28, 너비 28 채널 1개인 데이터 10개를 무작위로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10개의 데이터 중 첫 번째 데이터에 접근\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 데이터의 첫 채널의 공간 데이터에 접근\n",
    "x[0,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-3. 합성곱 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "\n",
    "x1 = np.random.rand(1,3,7,7)    # (데이터 수, 채널 수, 높이, 너비)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10,3,7,7)   # 데이터 수 10개\n",
    "col2 = im2col(x2, 5,5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 계층 구현\n",
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N,C,H,W = x.shape\n",
    "        out_h = int(1+ (H+2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)  # 입력 데이터를 im2col로 전개\n",
    "        col_W = self.W.reshape(FN, -1).T    # 필터를 2차원으로 배열로 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0,3,1,2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-4. 풀링 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N,C,H,W = x.shape\n",
    "        out_h = int(1+(H-self.pool_h) / self.stride)\n",
    "        out_w = int(1+(W-self.pool_w) / self.stride)\n",
    "        \n",
    "        # 전개 1\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        # 최댓값\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        # 성형\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0,3,1,2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. CNN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pickle\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim = (1,28,28),\n",
    "                 conv_param = {'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10,\n",
    "                 weight_init_std = 0.01):\n",
    "        \n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "        \n",
    "        # 가중치 매개변수 초기화\n",
    "        # 학습에 필요한 매개변수들을 인스턴스 변수 params에 저장\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "        \n",
    "        # CNN 구성 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'],\n",
    "                                           self.params['b1'],\n",
    "                                           conv_param['stride'],\n",
    "                                           conv_param['pad'])\n",
    "        \n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        \n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        \n",
    "    # 추론 수행\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    # 손실 함수의 값 구하기\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y,t)\n",
    "    \n",
    "    \n",
    "    # 오차역전파법으로 기울기 구하기\n",
    "    def gradient(self, x, t):\n",
    "        \n",
    "        # 순전파\n",
    "        self.loss(x,t)\n",
    "        \n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        \n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input_dim : 입력데이터 (채널 수 , 높이, 너비)의 차원\n",
    "- conv_param : 합성곱 계층의 하이퍼파라미터\n",
    "    - filter_num : 필터 수 \n",
    "    - filter_size : 필터 크기\n",
    "    - stride : 스트라이드\n",
    "    - pad : 패딩\n",
    "    - hidden_size : 은닉층(완전뉴런)의 뉴런 수\n",
    "    - output_size : 출력층(완전뉴런)의 뉴런 수\n",
    "    - weight_int_std : 초기화 때의 가중치 표준 편차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터셋 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2994802045163816\n",
      "=== epoch:1, train acc:0.263, test acc:0.242 ===\n",
      "train loss:2.296808903475506\n",
      "train loss:2.293231484142874\n",
      "train loss:2.2832260829787776\n",
      "train loss:2.2714188337254924\n",
      "train loss:2.263434176272049\n",
      "train loss:2.243962326003319\n",
      "train loss:2.2331020273055198\n",
      "train loss:2.1975885264379666\n",
      "train loss:2.2054042230534927\n",
      "train loss:2.1295534228327155\n",
      "train loss:2.1081266208704985\n",
      "train loss:2.095104483729305\n",
      "train loss:2.0051533975075784\n",
      "train loss:1.9720037509688675\n",
      "train loss:1.8488470530025949\n",
      "train loss:1.8995617317158304\n",
      "train loss:1.6756220735843328\n",
      "train loss:1.6142098813220291\n",
      "train loss:1.6141403688188785\n",
      "train loss:1.465010417441571\n",
      "train loss:1.3853251838781946\n",
      "train loss:1.384866934773767\n",
      "train loss:1.2762200526278082\n",
      "train loss:1.1419657356861277\n",
      "train loss:1.1092291112790194\n",
      "train loss:1.0859668802358475\n",
      "train loss:1.0204485527662899\n",
      "train loss:0.9241893678530397\n",
      "train loss:0.8618906817070038\n",
      "train loss:0.8697009418514092\n",
      "train loss:0.7465409050003379\n",
      "train loss:0.7565079301647525\n",
      "train loss:0.7340579378771301\n",
      "train loss:0.8427658864616201\n",
      "train loss:0.6469202331036561\n",
      "train loss:0.7137111991109599\n",
      "train loss:0.7187384054630366\n",
      "train loss:0.7830613912255449\n",
      "train loss:0.6444159481873655\n",
      "train loss:0.7689370856736331\n",
      "train loss:0.5428572002459123\n",
      "train loss:0.5492134113827252\n",
      "train loss:0.6170089448429575\n",
      "train loss:0.4451183909654942\n",
      "train loss:0.4534372707508759\n",
      "train loss:0.5889353929358805\n",
      "train loss:0.4398672302169255\n",
      "train loss:0.460575591110513\n",
      "train loss:0.5614815621405005\n",
      "train loss:0.529249258853111\n",
      "=== epoch:2, train acc:0.82, test acc:0.805 ===\n",
      "train loss:0.5717719842929146\n",
      "train loss:0.5882412678249591\n",
      "train loss:0.502389451119382\n",
      "train loss:0.49711052442485015\n",
      "train loss:0.5961849637905068\n",
      "train loss:0.47126045289145824\n",
      "train loss:0.4406990431537523\n",
      "train loss:0.43712147289940295\n",
      "train loss:0.34808343872518976\n",
      "train loss:0.7043293054480527\n",
      "train loss:0.538516555796814\n",
      "train loss:0.4458678472168187\n",
      "train loss:0.43345454701102737\n",
      "train loss:0.3690690432303041\n",
      "train loss:0.4359437274844023\n",
      "train loss:0.4347260478429174\n",
      "train loss:0.5104402567276122\n",
      "train loss:0.4330548927346267\n",
      "train loss:0.412932467771402\n",
      "train loss:0.4578718258393546\n",
      "train loss:0.4463868829705824\n",
      "train loss:0.47702415567309964\n",
      "train loss:0.40157662756664597\n",
      "train loss:0.45419445600981945\n",
      "train loss:0.45674964063038054\n",
      "train loss:0.5611032852913729\n",
      "train loss:0.49279582082877355\n",
      "train loss:0.3179309999678933\n",
      "train loss:0.41184293333826916\n",
      "train loss:0.3752215677801722\n",
      "train loss:0.5439090524160874\n",
      "train loss:0.4720107665330124\n",
      "train loss:0.5657009539688246\n",
      "train loss:0.33370989817487595\n",
      "train loss:0.41565104435211775\n",
      "train loss:0.2494309702045195\n",
      "train loss:0.3868409685979467\n",
      "train loss:0.3866262014352738\n",
      "train loss:0.7947418964324946\n",
      "train loss:0.2456094419634775\n",
      "train loss:0.44340339833357084\n",
      "train loss:0.349204570397356\n",
      "train loss:0.45265528223248\n",
      "train loss:0.4078543841203258\n",
      "train loss:0.3843627100880285\n",
      "train loss:0.28243255332915385\n",
      "train loss:0.3102701917085963\n",
      "train loss:0.3513168082993967\n",
      "train loss:0.5965875037449444\n",
      "train loss:0.46002501601944124\n",
      "=== epoch:3, train acc:0.871, test acc:0.861 ===\n",
      "train loss:0.33987153336239134\n",
      "train loss:0.29599907706043016\n",
      "train loss:0.4611679368809351\n",
      "train loss:0.2964483956712426\n",
      "train loss:0.2877626426070366\n",
      "train loss:0.3814227280710991\n",
      "train loss:0.43455339467634346\n",
      "train loss:0.34783984789766137\n",
      "train loss:0.2719221695875741\n",
      "train loss:0.20593656722904716\n",
      "train loss:0.3511595011753701\n",
      "train loss:0.24191967397344263\n",
      "train loss:0.3663998080821939\n",
      "train loss:0.4716245509435135\n",
      "train loss:0.39757924639609094\n",
      "train loss:0.34626821408726116\n",
      "train loss:0.3427766290272383\n",
      "train loss:0.22941816637660317\n",
      "train loss:0.3149913258412628\n",
      "train loss:0.29978032014004335\n",
      "train loss:0.3559944968609638\n",
      "train loss:0.22058996687766708\n",
      "train loss:0.3412628310996971\n",
      "train loss:0.2524845968933448\n",
      "train loss:0.314718295373989\n",
      "train loss:0.3771146872833576\n",
      "train loss:0.46275784247442653\n",
      "train loss:0.32704703439847543\n",
      "train loss:0.32830502001568773\n",
      "train loss:0.2393155762777048\n",
      "train loss:0.2754180167386566\n",
      "train loss:0.24503454611027892\n",
      "train loss:0.3555625576801531\n",
      "train loss:0.26922716593951523\n",
      "train loss:0.3330250279220202\n",
      "train loss:0.196645050529042\n",
      "train loss:0.24023357970964976\n",
      "train loss:0.24023034252429515\n",
      "train loss:0.3889518012277338\n",
      "train loss:0.3164069802281521\n",
      "train loss:0.2111323388525084\n",
      "train loss:0.2410611254428761\n",
      "train loss:0.38431769712658775\n",
      "train loss:0.3236333861796366\n",
      "train loss:0.25313350343376295\n",
      "train loss:0.21141751567317915\n",
      "train loss:0.28903032210364843\n",
      "train loss:0.2561508597506022\n",
      "train loss:0.2735784827363868\n",
      "train loss:0.3595732807066641\n",
      "=== epoch:4, train acc:0.904, test acc:0.897 ===\n",
      "train loss:0.219823700532177\n",
      "train loss:0.22100336790824676\n",
      "train loss:0.29775297401371253\n",
      "train loss:0.3740008354109541\n",
      "train loss:0.3113228977396075\n",
      "train loss:0.25878101215221333\n",
      "train loss:0.4695463415483702\n",
      "train loss:0.32090058316211784\n",
      "train loss:0.1706342465440328\n",
      "train loss:0.2612939767822893\n",
      "train loss:0.18921504715030577\n",
      "train loss:0.19985997558065297\n",
      "train loss:0.16049084167707267\n",
      "train loss:0.22620042984339797\n",
      "train loss:0.20716438486710134\n",
      "train loss:0.19824185493134197\n",
      "train loss:0.3072791640323153\n",
      "train loss:0.29681080981631774\n",
      "train loss:0.21192844885868362\n",
      "train loss:0.1461430425577156\n",
      "train loss:0.2886307114701783\n",
      "train loss:0.19595735570399284\n",
      "train loss:0.38248478526437674\n",
      "train loss:0.22894654392234393\n",
      "train loss:0.3222542591532149\n",
      "train loss:0.158884231968423\n",
      "train loss:0.28806513072171175\n",
      "train loss:0.2307320956876292\n",
      "train loss:0.2233690555705539\n",
      "train loss:0.21856842698929146\n",
      "train loss:0.10970272929127312\n",
      "train loss:0.17671284129890308\n",
      "train loss:0.3524709309401033\n",
      "train loss:0.29792852868228\n",
      "train loss:0.16039346722112305\n",
      "train loss:0.22050675487576896\n",
      "train loss:0.1590819797525514\n",
      "train loss:0.3141014764988055\n",
      "train loss:0.28562846393831853\n",
      "train loss:0.197634845790672\n",
      "train loss:0.27990618758368085\n",
      "train loss:0.2098178304120438\n",
      "train loss:0.26565635230029033\n",
      "train loss:0.3239370042835904\n",
      "train loss:0.364253552330533\n",
      "train loss:0.26948308364978646\n",
      "train loss:0.22698352105966302\n",
      "train loss:0.23530918615774835\n",
      "train loss:0.28287443225246767\n",
      "train loss:0.19772820678141717\n",
      "=== epoch:5, train acc:0.919, test acc:0.911 ===\n",
      "train loss:0.2482889522308235\n",
      "train loss:0.31306518180462795\n",
      "train loss:0.28034071221955914\n",
      "train loss:0.26770761874536536\n",
      "train loss:0.2193123079117668\n",
      "train loss:0.3371700791880929\n",
      "train loss:0.3045529303204099\n",
      "train loss:0.188773141307813\n",
      "train loss:0.14328017268433507\n",
      "train loss:0.17286673013007958\n",
      "train loss:0.16278899749291884\n",
      "train loss:0.29692585092755996\n",
      "train loss:0.22480044227976895\n",
      "train loss:0.16014534957839774\n",
      "train loss:0.2851594205579512\n",
      "train loss:0.23318896679370427\n",
      "train loss:0.2816714297795749\n",
      "train loss:0.22432704742803913\n",
      "train loss:0.21756314151134545\n",
      "train loss:0.17994031101796368\n",
      "train loss:0.19907592606795646\n",
      "train loss:0.2837781088474175\n",
      "train loss:0.1997279343099126\n",
      "train loss:0.26916773255978255\n",
      "train loss:0.17210982657452525\n",
      "train loss:0.2554815088844296\n",
      "train loss:0.18501489941223428\n",
      "train loss:0.2128056537103375\n",
      "train loss:0.40600818997045396\n",
      "train loss:0.14002820717466735\n",
      "train loss:0.2539241044890915\n",
      "train loss:0.22847647130858229\n",
      "train loss:0.2677833790303718\n",
      "train loss:0.3113942383788759\n",
      "train loss:0.21856136987806893\n",
      "train loss:0.29641998999470026\n",
      "train loss:0.2011774238821052\n",
      "train loss:0.19011494097449536\n",
      "train loss:0.24901448741868976\n",
      "train loss:0.12168943868463307\n",
      "train loss:0.13135866445502034\n",
      "train loss:0.1914120372894609\n",
      "train loss:0.29180800498001896\n",
      "train loss:0.16230695590134014\n",
      "train loss:0.1730272986250635\n",
      "train loss:0.14346273001302307\n",
      "train loss:0.15684664746026447\n",
      "train loss:0.15698305380966496\n",
      "train loss:0.15001855992964558\n",
      "train loss:0.29376776043841035\n",
      "=== epoch:6, train acc:0.933, test acc:0.902 ===\n",
      "train loss:0.22395784808387897\n",
      "train loss:0.1640262466849366\n",
      "train loss:0.17241965519816307\n",
      "train loss:0.2937580143106207\n",
      "train loss:0.15541167153685373\n",
      "train loss:0.16163907972722744\n",
      "train loss:0.13609925289865096\n",
      "train loss:0.13469014654405245\n",
      "train loss:0.10052127157184076\n",
      "train loss:0.12395550329657526\n",
      "train loss:0.26645038345332517\n",
      "train loss:0.14290233752563072\n",
      "train loss:0.16130775668655908\n",
      "train loss:0.21387042488357977\n",
      "train loss:0.08295510456780124\n",
      "train loss:0.11910200882802056\n",
      "train loss:0.25790417235772173\n",
      "train loss:0.18461568816641982\n",
      "train loss:0.11511206081115224\n",
      "train loss:0.14405648184712574\n",
      "train loss:0.08274965101620796\n",
      "train loss:0.1789070887402773\n",
      "train loss:0.17187396037825955\n",
      "train loss:0.10873224951880907\n",
      "train loss:0.4112728885078458\n",
      "train loss:0.1491783984238362\n",
      "train loss:0.1169463337481982\n",
      "train loss:0.17352486403186682\n",
      "train loss:0.1406556183700492\n",
      "train loss:0.3392171790613729\n",
      "train loss:0.16115381799638495\n",
      "train loss:0.2900198851191822\n",
      "train loss:0.16452110478161036\n",
      "train loss:0.19573432057680457\n",
      "train loss:0.20331823793997336\n",
      "train loss:0.1555731226926285\n",
      "train loss:0.19153946888843798\n",
      "train loss:0.21193521341163904\n",
      "train loss:0.19024594236944498\n",
      "train loss:0.16128946365174457\n",
      "train loss:0.17004544030747668\n",
      "train loss:0.10059663965274641\n",
      "train loss:0.11083377667775379\n",
      "train loss:0.127532174200053\n",
      "train loss:0.2776680597787313\n",
      "train loss:0.09705293808653989\n",
      "train loss:0.21072990323720395\n",
      "train loss:0.09899325054546462\n",
      "train loss:0.09045666586054064\n",
      "train loss:0.31796375581118685\n",
      "=== epoch:7, train acc:0.943, test acc:0.919 ===\n",
      "train loss:0.11582519678629627\n",
      "train loss:0.24031481094503618\n",
      "train loss:0.08339202149794725\n",
      "train loss:0.1698967271111452\n",
      "train loss:0.09320981401272377\n",
      "train loss:0.06402992148480639\n",
      "train loss:0.1444352566666987\n",
      "train loss:0.14637841749694908\n",
      "train loss:0.2075656848453676\n",
      "train loss:0.12126123521399154\n",
      "train loss:0.15798345687168455\n",
      "train loss:0.1496495509724967\n",
      "train loss:0.1721337474441749\n",
      "train loss:0.09507955438080909\n",
      "train loss:0.18588757271188366\n",
      "train loss:0.10162873389097245\n",
      "train loss:0.15745883393069243\n",
      "train loss:0.1498770189701346\n",
      "train loss:0.14749896436904555\n",
      "train loss:0.10548614909919948\n",
      "train loss:0.22650282553366655\n",
      "train loss:0.08372969191119033\n",
      "train loss:0.24392412744045244\n",
      "train loss:0.14376968610030302\n",
      "train loss:0.14795019221691072\n",
      "train loss:0.12172094335400602\n",
      "train loss:0.09869324923179987\n",
      "train loss:0.14042786089054501\n",
      "train loss:0.1870983619806243\n",
      "train loss:0.1314574419839446\n",
      "train loss:0.11693653708224465\n",
      "train loss:0.2166723415880694\n",
      "train loss:0.09432526809539754\n",
      "train loss:0.17293307319203316\n",
      "train loss:0.1156449893401407\n",
      "train loss:0.16684746130533906\n",
      "train loss:0.05960838362325276\n",
      "train loss:0.07743097788294759\n",
      "train loss:0.1515313243614213\n",
      "train loss:0.17733883947718138\n",
      "train loss:0.09415906764222076\n",
      "train loss:0.1157848029637119\n",
      "train loss:0.1881069042258937\n",
      "train loss:0.1374422171982502\n",
      "train loss:0.10374332656043027\n",
      "train loss:0.12019729778703839\n",
      "train loss:0.1730346874103321\n",
      "train loss:0.09938356677708537\n",
      "train loss:0.13243474763977972\n",
      "train loss:0.1126543828994115\n",
      "=== epoch:8, train acc:0.938, test acc:0.934 ===\n",
      "train loss:0.16727211866879088\n",
      "train loss:0.12066893542419539\n",
      "train loss:0.13086152761618128\n",
      "train loss:0.14200037041248184\n",
      "train loss:0.10513318011227428\n",
      "train loss:0.30192887144166447\n",
      "train loss:0.1720957072987301\n",
      "train loss:0.11612670681376676\n",
      "train loss:0.2162810519817744\n",
      "train loss:0.09569127900779142\n",
      "train loss:0.11338679517581798\n",
      "train loss:0.16342932809216448\n",
      "train loss:0.09249921969931174\n",
      "train loss:0.12519622307841535\n",
      "train loss:0.20649421511350213\n",
      "train loss:0.05554647979330369\n",
      "train loss:0.0672503440181966\n",
      "train loss:0.1280542508652547\n",
      "train loss:0.20097487515170126\n",
      "train loss:0.06609582150384281\n",
      "train loss:0.07898125903538661\n",
      "train loss:0.09673849856108716\n",
      "train loss:0.10103942453122315\n",
      "train loss:0.1514135326164056\n",
      "train loss:0.09574250381982852\n",
      "train loss:0.045876448733777525\n",
      "train loss:0.08415086139199383\n",
      "train loss:0.13550992031210196\n",
      "train loss:0.06021882601142661\n",
      "train loss:0.06759453754912269\n",
      "train loss:0.12082050507615935\n",
      "train loss:0.1733369117365313\n",
      "train loss:0.10751118614722578\n",
      "train loss:0.07965929999259704\n",
      "train loss:0.10732629284285146\n",
      "train loss:0.07237614227360774\n",
      "train loss:0.09765677223674053\n",
      "train loss:0.05737510033711806\n",
      "train loss:0.12419233845015025\n",
      "train loss:0.14859939938520583\n",
      "train loss:0.16565055261152126\n",
      "train loss:0.2112147789154542\n",
      "train loss:0.13345698409091977\n",
      "train loss:0.08148432965384014\n",
      "train loss:0.059479153550483665\n",
      "train loss:0.1295630987229062\n",
      "train loss:0.09029508867983921\n",
      "train loss:0.10679108641964592\n",
      "train loss:0.12628919793143775\n",
      "train loss:0.12652268991030222\n",
      "=== epoch:9, train acc:0.954, test acc:0.931 ===\n",
      "train loss:0.13377577063626583\n",
      "train loss:0.09194534539811601\n",
      "train loss:0.12132435165544092\n",
      "train loss:0.06146135808817739\n",
      "train loss:0.09138625024878311\n",
      "train loss:0.05761005107621195\n",
      "train loss:0.15524934825610817\n",
      "train loss:0.04151471973743238\n",
      "train loss:0.25951543256739973\n",
      "train loss:0.18843029925408963\n",
      "train loss:0.09900966683647126\n",
      "train loss:0.16711363336930596\n",
      "train loss:0.07769755840732367\n",
      "train loss:0.14535148126960235\n",
      "train loss:0.08028285683439394\n",
      "train loss:0.14829008113389353\n",
      "train loss:0.07943948944872069\n",
      "train loss:0.09610175710174569\n",
      "train loss:0.08571958068277784\n",
      "train loss:0.10849502007958907\n",
      "train loss:0.08312420009298678\n",
      "train loss:0.14177409238986355\n",
      "train loss:0.20133624297445202\n",
      "train loss:0.10562740464501406\n",
      "train loss:0.06394270589323592\n",
      "train loss:0.06802263573183687\n",
      "train loss:0.09555890036860067\n",
      "train loss:0.04530064729385648\n",
      "train loss:0.154474937787744\n",
      "train loss:0.03793418656516622\n",
      "train loss:0.0876972759019076\n",
      "train loss:0.08475553965523705\n",
      "train loss:0.13327187658110262\n",
      "train loss:0.07401245491634989\n",
      "train loss:0.04273832212742814\n",
      "train loss:0.13934423371400434\n",
      "train loss:0.20847478720151041\n",
      "train loss:0.09344984355736537\n",
      "train loss:0.10064337527577213\n",
      "train loss:0.08120145213897968\n",
      "train loss:0.09769955458128918\n",
      "train loss:0.08566624092503897\n",
      "train loss:0.14949957224260013\n",
      "train loss:0.06891125881209492\n",
      "train loss:0.22471692338545496\n",
      "train loss:0.09413691926079648\n",
      "train loss:0.13524951914795819\n",
      "train loss:0.09001955491048298\n",
      "train loss:0.13227259450660564\n",
      "train loss:0.09145801499057755\n",
      "=== epoch:10, train acc:0.963, test acc:0.941 ===\n",
      "train loss:0.03946980888119474\n",
      "train loss:0.18799147253515716\n",
      "train loss:0.08965074423121139\n",
      "train loss:0.0877706394063644\n",
      "train loss:0.20906113263631343\n",
      "train loss:0.06728202813554715\n",
      "train loss:0.08969045077137228\n",
      "train loss:0.12884054321449392\n",
      "train loss:0.1498929265867293\n",
      "train loss:0.11088862000854746\n",
      "train loss:0.09701656887177032\n",
      "train loss:0.12502458282223658\n",
      "train loss:0.09404634659050137\n",
      "train loss:0.1014270056773975\n",
      "train loss:0.15419946375789143\n",
      "train loss:0.12858718317766543\n",
      "train loss:0.11838832951271633\n",
      "train loss:0.07504907724313895\n",
      "train loss:0.1323899368632336\n",
      "train loss:0.0804430533361239\n",
      "train loss:0.0900231232283139\n",
      "train loss:0.09533547313019876\n",
      "train loss:0.09075252929242743\n",
      "train loss:0.0832503609821462\n",
      "train loss:0.06426966674076563\n",
      "train loss:0.1499867208426198\n",
      "train loss:0.13602107180639303\n",
      "train loss:0.056926312864786104\n",
      "train loss:0.046898458784438865\n",
      "train loss:0.15357155185454863\n",
      "train loss:0.04069595115321951\n",
      "train loss:0.0704025343838634\n",
      "train loss:0.08199178533423764\n",
      "train loss:0.11422495648887544\n",
      "train loss:0.14540495476652532\n",
      "train loss:0.13088811376678872\n",
      "train loss:0.09115150403014673\n",
      "train loss:0.08314085888609102\n",
      "train loss:0.035936994777832784\n",
      "train loss:0.024568529986909997\n",
      "train loss:0.07511340057581359\n",
      "train loss:0.1305768049020803\n",
      "train loss:0.07840475444891498\n",
      "train loss:0.08201212016966043\n",
      "train loss:0.034256584978440835\n",
      "train loss:0.0812973656192973\n",
      "train loss:0.07498198288684524\n",
      "train loss:0.09780511122574156\n",
      "train loss:0.080825750508548\n",
      "train loss:0.03370194210530721\n",
      "=== epoch:11, train acc:0.969, test acc:0.944 ===\n",
      "train loss:0.0889400436524496\n",
      "train loss:0.17169532195061848\n",
      "train loss:0.07265965368649421\n",
      "train loss:0.08970010428817961\n",
      "train loss:0.05662350064139358\n",
      "train loss:0.07170147557379054\n",
      "train loss:0.05030260572144563\n",
      "train loss:0.06511112921542633\n",
      "train loss:0.0463546810528547\n",
      "train loss:0.032991900041067196\n",
      "train loss:0.08850292666878885\n",
      "train loss:0.08904361272414552\n",
      "train loss:0.04628668678045372\n",
      "train loss:0.08833168107604614\n",
      "train loss:0.09980803622935276\n",
      "train loss:0.05034224719332612\n",
      "train loss:0.04039454916805471\n",
      "train loss:0.07955980407303395\n",
      "train loss:0.03511700500887081\n",
      "train loss:0.03421342115387078\n",
      "train loss:0.1376451028135299\n",
      "train loss:0.08435531197833296\n",
      "train loss:0.1089603735880678\n",
      "train loss:0.06832552286677347\n",
      "train loss:0.21424858533517402\n",
      "train loss:0.05679376270927361\n",
      "train loss:0.07440413520197468\n",
      "train loss:0.15841917383774012\n",
      "train loss:0.10733215730555706\n",
      "train loss:0.06893057595700337\n",
      "train loss:0.09966212944388685\n",
      "train loss:0.05722445772306698\n",
      "train loss:0.062061171453879745\n",
      "train loss:0.040141365070052906\n",
      "train loss:0.06779358173567428\n",
      "train loss:0.048608246392760505\n",
      "train loss:0.0766743702491462\n",
      "train loss:0.07988625146180854\n",
      "train loss:0.09677332397926845\n",
      "train loss:0.0631438447371836\n",
      "train loss:0.040566226397457106\n",
      "train loss:0.06649188620961848\n",
      "train loss:0.11107145195030908\n",
      "train loss:0.05580319521243164\n",
      "train loss:0.2631615289919453\n",
      "train loss:0.1144273682018022\n",
      "train loss:0.027730361239260648\n",
      "train loss:0.08433774813192464\n",
      "train loss:0.07483006729148056\n",
      "train loss:0.07195783466977719\n",
      "=== epoch:12, train acc:0.971, test acc:0.952 ===\n",
      "train loss:0.08043024501436868\n",
      "train loss:0.09338233279307802\n",
      "train loss:0.03287365090870202\n",
      "train loss:0.12714843105512164\n",
      "train loss:0.07646930830463859\n",
      "train loss:0.0702763418900514\n",
      "train loss:0.05914941332366239\n",
      "train loss:0.1671618611784336\n",
      "train loss:0.04665493253366014\n",
      "train loss:0.09728707867997784\n",
      "train loss:0.05802435954360715\n",
      "train loss:0.0829934292878448\n",
      "train loss:0.05428461982880853\n",
      "train loss:0.07699999811711193\n",
      "train loss:0.11797413561149739\n",
      "train loss:0.03627684184735787\n",
      "train loss:0.06400727176323529\n",
      "train loss:0.06219021137103164\n",
      "train loss:0.026441418469245633\n",
      "train loss:0.07799208859618999\n",
      "train loss:0.03605251412545394\n",
      "train loss:0.06345486349317317\n",
      "train loss:0.04174495064902553\n",
      "train loss:0.03959358873748746\n",
      "train loss:0.021252825977084503\n",
      "train loss:0.03794880152595383\n",
      "train loss:0.03444878369800671\n",
      "train loss:0.10010432626655363\n",
      "train loss:0.13363158100461434\n",
      "train loss:0.03339339100049065\n",
      "train loss:0.18261357562933442\n",
      "train loss:0.09129232461996527\n",
      "train loss:0.07214642173339288\n",
      "train loss:0.058764022052771224\n",
      "train loss:0.06368611106952103\n",
      "train loss:0.06615206020592097\n",
      "train loss:0.0262089301647265\n",
      "train loss:0.061567265424463696\n",
      "train loss:0.07248995080756546\n",
      "train loss:0.06615814715837313\n",
      "train loss:0.153599877749253\n",
      "train loss:0.10922667028084937\n",
      "train loss:0.02986716573495077\n",
      "train loss:0.04908219418580808\n",
      "train loss:0.07399576221300115\n",
      "train loss:0.07757037435533533\n",
      "train loss:0.0595003241450005\n",
      "train loss:0.05738074893880223\n",
      "train loss:0.1046571952212787\n",
      "train loss:0.0866433920848538\n",
      "=== epoch:13, train acc:0.977, test acc:0.953 ===\n",
      "train loss:0.09811265749325267\n",
      "train loss:0.059767973285250194\n",
      "train loss:0.02793436643040689\n",
      "train loss:0.04477293108542227\n",
      "train loss:0.04039316216616817\n",
      "train loss:0.045982958407460556\n",
      "train loss:0.05547183136358368\n",
      "train loss:0.03676811250119998\n",
      "train loss:0.03943151728988039\n",
      "train loss:0.023603318105727418\n",
      "train loss:0.044441831074644854\n",
      "train loss:0.04360230828291782\n",
      "train loss:0.040572900390056954\n",
      "train loss:0.03436102866859142\n",
      "train loss:0.04202990858998487\n",
      "train loss:0.045980779528382476\n",
      "train loss:0.05507196229714327\n",
      "train loss:0.09071992462918559\n",
      "train loss:0.04852465902221176\n",
      "train loss:0.021225392532558843\n",
      "train loss:0.048910894212048896\n",
      "train loss:0.03005484908938015\n",
      "train loss:0.04704915693823976\n",
      "train loss:0.08137663133649639\n",
      "train loss:0.0384073525592318\n",
      "train loss:0.07467574621255964\n",
      "train loss:0.10715298081492007\n",
      "train loss:0.06497806927335355\n",
      "train loss:0.0711122790870258\n",
      "train loss:0.0324568323276092\n",
      "train loss:0.059073981209017246\n",
      "train loss:0.019834799883316923\n",
      "train loss:0.09347604903453952\n",
      "train loss:0.037318039303771984\n",
      "train loss:0.025664858486477017\n",
      "train loss:0.05849646354909079\n",
      "train loss:0.0423899981674108\n",
      "train loss:0.023165161893860916\n",
      "train loss:0.02743276899828429\n",
      "train loss:0.07722924201891429\n",
      "train loss:0.038485140032447795\n",
      "train loss:0.03510134653904695\n",
      "train loss:0.042836878100351236\n",
      "train loss:0.060095481855779044\n",
      "train loss:0.07862838094044901\n",
      "train loss:0.04332524136744361\n",
      "train loss:0.07102714605220804\n",
      "train loss:0.0631060896723405\n",
      "train loss:0.0992506215100405\n",
      "train loss:0.06105646998846904\n",
      "=== epoch:14, train acc:0.971, test acc:0.948 ===\n",
      "train loss:0.051325783283439674\n",
      "train loss:0.044157169030968266\n",
      "train loss:0.06752975559295737\n",
      "train loss:0.051721511460105285\n",
      "train loss:0.07491536597090176\n",
      "train loss:0.03633605332124892\n",
      "train loss:0.021864525087827248\n",
      "train loss:0.07805029107209846\n",
      "train loss:0.06367654209962365\n",
      "train loss:0.03823905505259161\n",
      "train loss:0.04735124204448752\n",
      "train loss:0.053743450254822786\n",
      "train loss:0.05147125258562393\n",
      "train loss:0.03884611306216072\n",
      "train loss:0.07997371245971877\n",
      "train loss:0.03785798945285075\n",
      "train loss:0.014647173333603795\n",
      "train loss:0.035375955201834314\n",
      "train loss:0.05370619347617981\n",
      "train loss:0.0283145910085793\n",
      "train loss:0.05966632075417632\n",
      "train loss:0.050161888794131144\n",
      "train loss:0.034460386762059876\n",
      "train loss:0.05447812851971883\n",
      "train loss:0.04153400506424034\n",
      "train loss:0.04850362108905455\n",
      "train loss:0.09043690865324167\n",
      "train loss:0.016766234073715316\n",
      "train loss:0.013325113904334503\n",
      "train loss:0.04243389661050598\n",
      "train loss:0.05435953983216718\n",
      "train loss:0.044956422655906464\n",
      "train loss:0.08477782570040798\n",
      "train loss:0.03558834278780555\n",
      "train loss:0.05949403047032633\n",
      "train loss:0.06623758944332385\n",
      "train loss:0.04134910760315711\n",
      "train loss:0.1134664265972912\n",
      "train loss:0.05340790281988592\n",
      "train loss:0.04224802569213084\n",
      "train loss:0.06231887487673921\n",
      "train loss:0.04444340679103024\n",
      "train loss:0.03948861125397804\n",
      "train loss:0.027878705436120223\n",
      "train loss:0.016432135003787072\n",
      "train loss:0.06974183069039987\n",
      "train loss:0.034858550677102945\n",
      "train loss:0.07564977587149153\n",
      "train loss:0.02873042414749065\n",
      "train loss:0.09351279610741749\n",
      "=== epoch:15, train acc:0.981, test acc:0.955 ===\n",
      "train loss:0.09275242385789503\n",
      "train loss:0.052219006661317444\n",
      "train loss:0.017140699680355788\n",
      "train loss:0.03390025317787476\n",
      "train loss:0.03132318330377826\n",
      "train loss:0.04917327707587547\n",
      "train loss:0.01847604293067034\n",
      "train loss:0.034796551716398144\n",
      "train loss:0.04562489584738933\n",
      "train loss:0.056182365157416606\n",
      "train loss:0.05081112008864453\n",
      "train loss:0.06490195545021117\n",
      "train loss:0.0277115360671939\n",
      "train loss:0.07290507852277082\n",
      "train loss:0.03594582111937754\n",
      "train loss:0.02998312134761427\n",
      "train loss:0.02983663474183442\n",
      "train loss:0.024303553026798\n",
      "train loss:0.06427051181523175\n",
      "train loss:0.04262214988574804\n",
      "train loss:0.05077459229653337\n",
      "train loss:0.02256219140531243\n",
      "train loss:0.034471453059263746\n",
      "train loss:0.05046097309411644\n",
      "train loss:0.019628220632613578\n",
      "train loss:0.08141926704455413\n",
      "train loss:0.026547784483778675\n",
      "train loss:0.02460494929301092\n",
      "train loss:0.03885854954128684\n",
      "train loss:0.036684185520176105\n",
      "train loss:0.05942615896190148\n",
      "train loss:0.03175115072087053\n",
      "train loss:0.0299557896030462\n",
      "train loss:0.06489007891046451\n",
      "train loss:0.04503336291718171\n",
      "train loss:0.0328286287413841\n",
      "train loss:0.04252406320344829\n",
      "train loss:0.017454069695701558\n",
      "train loss:0.045964693664894245\n",
      "train loss:0.015043629825421189\n",
      "train loss:0.02860669410136927\n",
      "train loss:0.021171361028162545\n",
      "train loss:0.03238321803461874\n",
      "train loss:0.026991258173935287\n",
      "train loss:0.020734770198276395\n",
      "train loss:0.03804995768865505\n",
      "train loss:0.09373938390507895\n",
      "train loss:0.01101831508963854\n",
      "train loss:0.045577914212455876\n",
      "train loss:0.01260617625943061\n",
      "=== epoch:16, train acc:0.987, test acc:0.959 ===\n",
      "train loss:0.021582668164012296\n",
      "train loss:0.06348682761385133\n",
      "train loss:0.023522743979598783\n",
      "train loss:0.014806757082962245\n",
      "train loss:0.02356862451244615\n",
      "train loss:0.028397892223086255\n",
      "train loss:0.015070322045313701\n",
      "train loss:0.03084870256495341\n",
      "train loss:0.04749855742352269\n",
      "train loss:0.03127611041854248\n",
      "train loss:0.061616193144056385\n",
      "train loss:0.022476365921265288\n",
      "train loss:0.037938417653097065\n",
      "train loss:0.029497506689990315\n",
      "train loss:0.013631791392112895\n",
      "train loss:0.019986093150432416\n",
      "train loss:0.04762763051345121\n",
      "train loss:0.016038551766428447\n",
      "train loss:0.033363709258919426\n",
      "train loss:0.0246008786785716\n",
      "train loss:0.06204513817693841\n",
      "train loss:0.038258811990150875\n",
      "train loss:0.03557172393222605\n",
      "train loss:0.04304218677588902\n",
      "train loss:0.020729403836128646\n",
      "train loss:0.04079124116512002\n",
      "train loss:0.03417675504800219\n",
      "train loss:0.02393544210985196\n",
      "train loss:0.016718460974647437\n",
      "train loss:0.022834083574013925\n",
      "train loss:0.018976736465634872\n",
      "train loss:0.031093788671439096\n",
      "train loss:0.026561140449278934\n",
      "train loss:0.026421709121384154\n",
      "train loss:0.03326854842229984\n",
      "train loss:0.026335153343546455\n",
      "train loss:0.05317178775092302\n",
      "train loss:0.019266295338822882\n",
      "train loss:0.08415235330077957\n",
      "train loss:0.012619034357153669\n",
      "train loss:0.11941097670286062\n",
      "train loss:0.07484733558403034\n",
      "train loss:0.03396108820630015\n",
      "train loss:0.033234198151568785\n",
      "train loss:0.022210299517064706\n",
      "train loss:0.0492859292580818\n",
      "train loss:0.04527865327295167\n",
      "train loss:0.024543833127574684\n",
      "train loss:0.018584999814904024\n",
      "train loss:0.07215398613936626\n",
      "=== epoch:17, train acc:0.987, test acc:0.959 ===\n",
      "train loss:0.023183452232070176\n",
      "train loss:0.012272682667604291\n",
      "train loss:0.01708174791302216\n",
      "train loss:0.014131132237633601\n",
      "train loss:0.06914099468502681\n",
      "train loss:0.021650468574465894\n",
      "train loss:0.03433282333975196\n",
      "train loss:0.01986077279467375\n",
      "train loss:0.013194819855362517\n",
      "train loss:0.0359867817569656\n",
      "train loss:0.02015223280492416\n",
      "train loss:0.04855007376148123\n",
      "train loss:0.024480405847489905\n",
      "train loss:0.03499035590276334\n",
      "train loss:0.01872862978084981\n",
      "train loss:0.03844063603109598\n",
      "train loss:0.020144364630023177\n",
      "train loss:0.02711711542566558\n",
      "train loss:0.023870026673997246\n",
      "train loss:0.03870016975333914\n",
      "train loss:0.04855036696450589\n",
      "train loss:0.00898960112775886\n",
      "train loss:0.013401301820997318\n",
      "train loss:0.022760425192870658\n",
      "train loss:0.06769538972954968\n",
      "train loss:0.02611323971842698\n",
      "train loss:0.042093686164305436\n",
      "train loss:0.044046156214252\n",
      "train loss:0.037153636702538614\n",
      "train loss:0.015799898748099252\n",
      "train loss:0.014843560945880654\n",
      "train loss:0.013064367887502785\n",
      "train loss:0.028988217573546037\n",
      "train loss:0.05448131127152893\n",
      "train loss:0.03524276723194947\n",
      "train loss:0.03016139459284314\n",
      "train loss:0.02454668491000859\n",
      "train loss:0.04640253220353059\n",
      "train loss:0.046286412772883485\n",
      "train loss:0.023113608667214645\n",
      "train loss:0.06572117489467917\n",
      "train loss:0.029453090683069956\n",
      "train loss:0.028487041872992006\n",
      "train loss:0.009446524338746825\n",
      "train loss:0.012594587379984345\n",
      "train loss:0.022733248447651427\n",
      "train loss:0.024414839305978667\n",
      "train loss:0.01608095006522783\n",
      "train loss:0.02457161488184025\n",
      "train loss:0.04573022475901081\n",
      "=== epoch:18, train acc:0.991, test acc:0.955 ===\n",
      "train loss:0.04258255956278931\n",
      "train loss:0.03678458741704973\n",
      "train loss:0.007716560010887563\n",
      "train loss:0.01017442117904619\n",
      "train loss:0.02770967103012737\n",
      "train loss:0.03871574853075127\n",
      "train loss:0.013042576234517536\n",
      "train loss:0.05868321531704269\n",
      "train loss:0.022851260916742878\n",
      "train loss:0.055469339103827196\n",
      "train loss:0.011471692899086887\n",
      "train loss:0.0195527211228745\n",
      "train loss:0.009084596703515569\n",
      "train loss:0.020781235711251934\n",
      "train loss:0.03663297920155419\n",
      "train loss:0.037294813058030646\n",
      "train loss:0.03244751119906356\n",
      "train loss:0.03732351997112178\n",
      "train loss:0.020438146445835588\n",
      "train loss:0.01494902917768897\n",
      "train loss:0.03620670197631598\n",
      "train loss:0.02969694525012183\n",
      "train loss:0.015371517809307837\n",
      "train loss:0.008279031329387468\n",
      "train loss:0.032693570499396384\n",
      "train loss:0.033391231115470925\n",
      "train loss:0.016228906774464456\n",
      "train loss:0.012983649712439538\n",
      "train loss:0.03458887651863828\n",
      "train loss:0.014022489940131744\n",
      "train loss:0.019223662759359873\n",
      "train loss:0.02906830350716825\n",
      "train loss:0.028373785472052354\n",
      "train loss:0.011083469963182793\n",
      "train loss:0.011735065709873642\n",
      "train loss:0.010795613002428175\n",
      "train loss:0.007750719116041191\n",
      "train loss:0.0035597124131427327\n",
      "train loss:0.041072737592148606\n",
      "train loss:0.022361390976683212\n",
      "train loss:0.009884911395874206\n",
      "train loss:0.027981516737722326\n",
      "train loss:0.009432537944162357\n",
      "train loss:0.020317449684171835\n",
      "train loss:0.034423039675088384\n",
      "train loss:0.01206158636725702\n",
      "train loss:0.056814024928014725\n",
      "train loss:0.013447613102679142\n",
      "train loss:0.007244010784515965\n",
      "train loss:0.012491990269309689\n",
      "=== epoch:19, train acc:0.995, test acc:0.956 ===\n",
      "train loss:0.015545835242140206\n",
      "train loss:0.013510966787165773\n",
      "train loss:0.03201970341283223\n",
      "train loss:0.0625929463029173\n",
      "train loss:0.015577636379121143\n",
      "train loss:0.008894380179788205\n",
      "train loss:0.020750142475377452\n",
      "train loss:0.02712291838673762\n",
      "train loss:0.018553871436837444\n",
      "train loss:0.02009893505919318\n",
      "train loss:0.009704327783183739\n",
      "train loss:0.04532165961808585\n",
      "train loss:0.027660976578595814\n",
      "train loss:0.011120148869295646\n",
      "train loss:0.030527287372044437\n",
      "train loss:0.013004377565079111\n",
      "train loss:0.024740550793087207\n",
      "train loss:0.024069808656639102\n",
      "train loss:0.01749995495098611\n",
      "train loss:0.01263406237446987\n",
      "train loss:0.014101388024566312\n",
      "train loss:0.01575680449193489\n",
      "train loss:0.02175637544700747\n",
      "train loss:0.019822889979021666\n",
      "train loss:0.014177339847118562\n",
      "train loss:0.05264877354313733\n",
      "train loss:0.04001073247921182\n",
      "train loss:0.035992709551035916\n",
      "train loss:0.01707881718830433\n",
      "train loss:0.007946600954754204\n",
      "train loss:0.008662087450620465\n",
      "train loss:0.025875947508212135\n",
      "train loss:0.03403543592380152\n",
      "train loss:0.049229390302878706\n",
      "train loss:0.01711730551956159\n",
      "train loss:0.0367534484512206\n",
      "train loss:0.016318798041714454\n",
      "train loss:0.011935967621616446\n",
      "train loss:0.02142777089004694\n",
      "train loss:0.01182883225118894\n",
      "train loss:0.033645315485756916\n",
      "train loss:0.020591459318879766\n",
      "train loss:0.012699167556722693\n",
      "train loss:0.013724606254089524\n",
      "train loss:0.013936242716628112\n",
      "train loss:0.01140134009222847\n",
      "train loss:0.015162900080494089\n",
      "train loss:0.022411210474228064\n",
      "train loss:0.03614893770673183\n",
      "train loss:0.012733840513103627\n",
      "=== epoch:20, train acc:0.995, test acc:0.96 ===\n",
      "train loss:0.02971513475794618\n",
      "train loss:0.012850304540663864\n",
      "train loss:0.023425673240925128\n",
      "train loss:0.011029117487220932\n",
      "train loss:0.020186687376885063\n",
      "train loss:0.015368579061997583\n",
      "train loss:0.01897393163415672\n",
      "train loss:0.04753362741726433\n",
      "train loss:0.028728461993263017\n",
      "train loss:0.046460443379943046\n",
      "train loss:0.009768004229935382\n",
      "train loss:0.04523108040968724\n",
      "train loss:0.012718588335964192\n",
      "train loss:0.007000943994663067\n",
      "train loss:0.010812084866684765\n",
      "train loss:0.012476375148315509\n",
      "train loss:0.015135867443648395\n",
      "train loss:0.016987474067002215\n",
      "train loss:0.00863962951334384\n",
      "train loss:0.012026440993489816\n",
      "train loss:0.010588274130298248\n",
      "train loss:0.013546444254611899\n",
      "train loss:0.024041030852474173\n",
      "train loss:0.028055297258823327\n",
      "train loss:0.016522184028715577\n",
      "train loss:0.028794530374065777\n",
      "train loss:0.016728561380600044\n",
      "train loss:0.02495785414167129\n",
      "train loss:0.02259371472010434\n",
      "train loss:0.008555890301020134\n",
      "train loss:0.042028804550068743\n",
      "train loss:0.028304108868012854\n",
      "train loss:0.020866691948705586\n",
      "train loss:0.02583154185472293\n",
      "train loss:0.01628265263534051\n",
      "train loss:0.008291824212557763\n",
      "train loss:0.038670363859009356\n",
      "train loss:0.07306012978699065\n",
      "train loss:0.06673212710349322\n",
      "train loss:0.007664026696627735\n",
      "train loss:0.0059583864397083205\n",
      "train loss:0.022774084956661847\n",
      "train loss:0.019518268745640364\n",
      "train loss:0.01801714487367301\n",
      "train loss:0.018519435354453467\n",
      "train loss:0.01107128561401482\n",
      "train loss:0.005298839281363991\n",
      "train loss:0.013811682848626185\n",
      "train loss:0.024217564792197457\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.955\n",
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간낭비 방지용 데이터 수 줄임\n",
    "x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28),\n",
    "                        conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params('params.pkl')\n",
    "print('Saved Network Parameters!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "markers = {'train':'o', 'test':'s'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-1. 1번쨰 층의 가중치 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApgAAAHRCAYAAADOjsnwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAm+0lEQVR4nO3dbaykZX0/8GvO8/OysLC7x11UFmiVp5ZKCViWYtsoaG1oMPUpTRvamqaNJk20Nryw6YOpL2yjCWl5Ua1tUqNiiygNWIKItPJUhBVZ2F1A9qwHWBbYnTnP58zM/9X4H8+D7P27rrCon08yOcntfq/rnt/cc893Bzen1m632wkAAArpOdEnAADATxcFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACK6osGW61Wmp6eTuPj46lWq5U8p59a7XY7NRqNNDk5mVJK5ldR9/x6enpcgxWZXz4zzGN++cwwj/nlWz3DH/cHQ6amptopJY/AY2pqyvwy5+caND8z/Ml9mJ8ZnuiH+ZWb4UbC32COj4+nlFIaGxsLtf6LL744unVKKaUPfOAD4exll12Wtffw8HAoV6/X086dO384u5RS+ru/+7s0NDRUea1rrrkmdA4d3efwSjt8+HAo12g00oUXXvjDc+/8vPbaa9PAwEDl9V588cXQeXQsLCyEs7nX4Bve8IbKmbm5ufSud71rzfzOPffc1NvbW3m97du3V850O//888PZ8847L2vvd77znaHc6vdw5+cll1yS+vqq306ffvrp0HmUkDP/lFJ63/veVzkzNzeXrr322jXze/e73x16D+/fv79yplvkNeuYm5vL2nvz5s2h3MrKSrrzzjvXzPD9739/aIZbtmwJnUfHj/0G62W0Wq1XfO/FxcX0D//wD2vmt23bttB6s7OzlTPd/uIv/iKcffvb35619+mnnx7Krddl1hN+d3VKZa1WCxXM/v7+6NYppZRGRkbC2YmJiay9owWzo3teQ0NDofVyn8OJLJjz8/NZ+e5rL6WUBgYG0uDgYOV1Ijfjbs1mM5zNvYZGR0fD2dXz6+3tDRXM3Pdw5DXryHn/p5T//lk9w76+vlBZyflwznUi78HrvYcj78ecgpibz907d/6lZpjzPkwphe4dHTn30JTy3j+r59fT0xNaL/c/q0e+YOrI/RwvdR/ciH/kAwBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUFRf7gKnnHJK6BfEz87OZu37wgsvhLP79+/P2vu5554L5dZ7zvv27UuDg4OV1zp8+HDoHDqeeuqpcPaxxx7L2vvee+8N5RYXF9c9fvbZZ6fh4eHK6/3nf/5n6Dw6Nm3aFM729/dn7X3++edXztTr9XWPb968OfX1Vb8VfO9736uc6bZt27Zw9tixY1l7Hz16NJTbaIZzc3Opt7e38nrRe0nHeeedF85eddVVWXtfdNFFlTONRmPd4wsLC6nValVeb2lpqXKmW851tHfv3qy9zznnnFCu2Wyue7xWq6VarVZ5vccffzx0Hh0XXnhhOJt7D9m+fXvlzEafI7/7u7+bhoaGKq939913V850u//++8PZn//5n8/ae8eOHaHcRtfgar7BBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIrqy16gry/19vZWzu3bty9r309/+tNZ+RxHjx4N5Vqt1ppjX/7yl1NPT/We/+1vfzt0Dh1LS0tZ+RyNRiOUazab6x7fv39/GhwcrLze1q1bQ+fREX0eJfbevHlz5cxG79ORkZHU399feb2TTjqpcqbbzMxMOPvggw9m7V2v10O5hYWFdY9PTU2F3sfz8/Oh8+gYHh4OZy+77LKsvbdv3145Mzo6uu7xvXv3hj5HHnroocqZ4zmf47HR/eh4Pf3006Fcu93ecL3I+/jIkSOh8+hYWVkJZ6enp7P2jlwzG332ff/7308DAwOV13vHO95ROdPtuuuuC2fvv//+rL0/+clPhnJzc3PH9ed8gwkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARfXlLrC0tJR6eqr31Lm5uax9H3vssXB2ZmYma++TTjoplGu322uOLSwspFqtVnmte+65J3QOHdHnkFJKJ598ctbeW7ZsCeWazea6xycmJtLg4GDl9Y4dOxY6j44nnnginL322muz9v7Qhz5UObOwsJC152qHDx/Oyq/3fnil9i59DUZt2rQpK79z585wtr+/P2vvVqtVLPPMM8+EPkdynXbaaeHsjh07svaempoK5VqtVjp69Oia4xMTE6HXdGhoKHQeHZOTk+Hsnj17svb+l3/5l6x8t7e97W1pZGSkcu7GG2/M2nd2djacXVlZydr77rvvDuUWFxeP68/5BhMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAilIwAQAoqi93gXPPPTf19/dXzi0sLGTt+8ILL4Szs7OzWXufeeaZodzy8nK69dZbf+TYrl27Um9vb+W1cp5/Simdcsop4ey2bduy9t60aVMot7S0lP7v//5vzfFf/uVfTqOjo5XXe/jhh0Pn0dFsNsPZPXv2ZO194403Vs5sdL6vf/3r0+DgYOX1Itdtt0OHDoWzzzzzTNbeP/jBD7Lyqx09ejTVarWiax6PLVu2hLOLi4tZez/55JOVM41GY93jzWYztVqtyuu9613vqpzp9ku/9Evh7O7du7P2vuSSS0K5er2+7j30n/7pn9LExETl9SLv/W7tdjuc/ehHP5q193e/+93KmeXl5XT77bevOX7llVeG5rdz587KmW6XXXZZOPtnf/ZnWXt//vOfD+WO973qG0wAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIrqiwbb7XZKKaXl5eVQfmVlJbp1SimlZrN5QrIp5T/nzuxyzqXVaoVyufumFH/+HUtLS1n7dubX+Tk3Nxdab2FhIZTriD6PEiKvXyezen65r0dUzjXY/R46EVbP8ESdz+LiYjg7MzOTtXdfX/WPj86epeaXew3m3ANmZ2ez9q7X61m51bNrNBqh9QYHB0O5jpxrP+f6TSn2+q/+HM6dX+51MD8/H87m3neiPaKTe9n920FTU1PtlJJH4DE1NWV+mfNzDZqfGf7kPszPDE/0w/zKzXAjtXawArdarTQ9PZ3Gx8dTrVaLLPEzp91up0ajkSYnJ1NKyfwq6p5fT0+Pa7Ai88tnhnnML58Z5jG/fKtnuJFwwQQAgPX4Rz4AABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABTVFw22Wq00PT2dxsfHU61WK3lOP7Xa7XZqNBppcnIypZTMr6Lu+fX09LgGKzK/fGaYx/zymWEe88u3eoY/7g+GTE1NtVNKHoHH1NSU+WXOzzVofmb4k/swPzM80Q/zKzfDjYS/wRwfH08ppfSBD3wgDQ4OVs4vLi5Gt04ppbR///5w9siRI1l7N5vNcO6xxx774exSSmlqaipNTExUXivn+aeU0sc+9rFwds+ePVl7b926NZRrNpvpO9/5zg/n1/n5la98JY2OjlZe75FHHgmdR8dJJ50Uzm7atClr70svvbRyptFopDPPPHPN/KLX4MrKSuVMt8997nPh7Gc/+9msvV944YVQrtVqpWeffXbNDC+99NLU11f9djozMxM6jxL52dnZrL2PHTtWOdNut9Ps7Oya+d13331pbGys8nrbtm2rnOnW29sbzuZe/61WK5RrNBrpjDPOWDPDa665JvX391de76677gqdR8ev/uqvhrPvfOc7s/Z+zWteUzkzOzub3vrWt66Z3+mnn/7jv43bQLQPdLzpTW8KZ//4j/84a++LL744lKvX62nnzp0/0mXWEy6Yna+SBwcHQwUzV+Rm3pFzUymh+2v4iYmJ0Id75GbcLXIj6oi8CbvlvHYp/f/5dX6Ojo6GCubw8HDWeYyMjISzkfPtFrlmOlbPL3oN5n7A5sw/9z2cew2vnmFfX1/ous59Hjn5UjPIyXZ+jo2NveyH1Xpy3gcp/WQWzI7VM+zv708DAwOV18m9DiJ7duTcQ1PK+xxcPb+enp7QLNrtdvgcUsr7LD6RnyMpvfw9wD/yAQCgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIrK+6XQKaV9+/aFfpdmzu/fTCnv96fm/i7s6C+nX1paSt/73vd+5NgzzzyTZmZmKq/1z//8z6Fz6PjBD34Qzh47dixr7+jvj202m+seHxoaCv1e6/3794fOo2PLli3h7O7du7P2HhoaqpxZWlra8PhG/9uPc/3111fOdPvSl74Uzj700ENZe5922mmh3Ea/P/qpp54K3ZPq9XroPDrm5+fD2YWFhay9S5qbmwvNb3Z2Nmvfw4cPh7O5e993332h3Eav+fLycmi9M844I5TryPld5IODg1l7X3DBBZUzG73ndu7cGeoGzzzzTOXM8ZzP8bjnnnuy9l5cXAzljvfa9w0mAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUFRf7gIPPPBA6ump3lOXlpay9r3gggvC2eeffz5r7zvvvDOUazaba459/OMfTwMDA5XX+o//+I/QOXS8+OKL4Wx/f3/W3keOHAnlWq3Wusc///nPp8HBwcrrfetb3wqdR8fCwkI4e+DAgay977nnnsqZjc73+uuvT0NDQ5XXu+GGGypnukWvg5RSGh0dzdr71FNPDeWazea65z0xMZF6e3srr7d58+bQeXS02+1wdnx8PGvvyPNdWVlJ//M//7Pm+Mc//vHQfWVkZKRyptvU1FQ4Ozs7m7X3/Px8KLfe50hKKe3atSt0H8x9HjnX0QMPPJC197333ls5s9F98JRTTgldg7n3osj7qOOuu+7K2vuWW24J5VZWVo7rz/kGEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACK6std4KWXXkq1Wq1ybmVlJWvfyy+/PJzds2dP1t5HjhwJ5VZWVtKTTz75I8duv/321NNTvee/+OKLoXPoOPPMM8PZxcXFrL1HRkZCuWazmZ5//vk1xx9//PHU399feb2ZmZnQeXTs3bs3nI1eQx3PPvts5czy8vK6x7/61a+mvr7qt4JGo1E5023btm3hbOT5dxseHg7lms3musevueaaNDQ0VHm9Xbt2hc6jY/v27eHsli1bsvZe7734cmZnZ9OVV1655vgtt9wS+hxZWFionOkWec06JiYmTsjerVZr3eNvfvOb0+joaOX1vv/974fOo+Pmm28OZ3Nfv4MHD2blu83Pz4d6yaFDh7L2jXx2ddx///1Ze5922mmh3EbX4Gq+wQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACK6stdYNeuXam3t7dybtOmTVn7nnHGGeHsxz72say9e3pivbxer6953v39/aH1Xve614XOoePiiy8OZ+fm5rL23rJlSyi3tLSUDhw4sOb4+eefnwYHByuvt3379tB5dLz5zW8OZ/fu3Zu198GDBytnms3musenp6dD1+D4+HjlTLeca3jbtm1Ze2/dujWUW15eTt/5znfWHP+1X/u1NDY2Vnm9c845J3QeHRu9psdjeHg4a+/Ie67RaKx7fHFxMetcooaGhsLZk08+OWvvzZs3h3IrKyvp0KFDa44/99xzaWRkpPJ6u3fvDp1Hx+tf//pw9o477sja+/LLL6+cWVpaSl/4whfWHN+xY0caGBiovN6pp55aOdPt6aefDmdze0D03JvNZjpy5MjL/jnfYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUJSCCQBAUQomAABFKZgAABSlYAIAUFRfNNhut1NKKTWbzVB+ZWUlunVKKaX5+flwtl6vZ+3d0xPr5Z19O7NLKaVWqxVaq3uNiOXl5ROSTSmlpaWlrFznuXd+Li4uvqLn0RG9DlLKv/4j77tOZvX8otdgNNeRM4Pc+UWv4U5u9QxnZ2dD6+Xei6L335Ty38eNRqNyZmZmJqW0dn4nSs7+ObNPKX4Nb/Q+jn4mLiwshHId0ftvSvnv48g9fKP3cO7nUlTODHLvwdFrePU1uKF20NTUVDul5BF4TE1NmV/m/FyD5meGP7kP8zPDE/0wv3Iz3EitHfwrXKvVStPT02l8fDzVarXIEj9z2u12ajQaaXJyMqWUzK+i7vn19PS4Bisyv3xmmMf88plhHvPLt3qGGwkXTAAAWI9/5AMAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFEKJgAARSmYAAAUpWACAFCUggkAQFF90WCr1UrT09NpfHw81Wq1kuf0U6vdbqdGo5EmJydTSsn8KuqeX09Pj2uwIvPLZ4Z5zC+fGeYxv3yrZ/jj/mDI1NRUO6XkEXhMTU2ZX+b8XIPmZ4Y/uQ/zM8MT/TC/cjPcSPgbzPHx8ZRSSl/84hfTyMhI5fyjjz4a3TqllNLevXvD2VNPPTVr79NPPz2Um5+fTx/+8Id/OLuUUvryl7+cRkdHK681MDAQOoeO//qv/wpnH3rooay9h4aGQrnl5eV02223/XB+nZ+f/OQn0/DwcOX1du7cGTqPjq997Wvh7G/91m9l7X3WWWdVzjQajXThhReumd/999+fxsbGKq8XuW67/du//Vs4u2PHjqy9zz777FBudnY2/fqv//qaGd57772hGXbfCyI2bdoUzj7xxBNZezcajcqZ2dnZdNVVV62Z32233Ra6nn7/93+/cqbb888/H85+8IMfzNr7Pe95Tyg3MzOTLrroojUzPP3003/8t0kbiHx+d/vFX/zFcPbSSy/N2vvtb3975Uyj0UjnnXfemvm95z3vCX2ufu5zn6uc6ZYzv127dmXt/ed//ueh3MzMTLriiite9v4VLpidr5JHRkZCN4ZIIeiWU7AGBwez9s499+6v4UdHR0Pzy30OOfn+/v6svXPznfl1fg4PD4dek9yClHMN5u6dU0xWz29sbCy0XqRQdYv+RSOl/A/F3HMvNcOJiYms88jJ55bbdrsdzq6e3+joaOg16e3tDZ9D9/4ROddvSvnzXz3Dnp6eUMHMnWHOfTD3szTn+l89v4GBgewvbiJy5p/7WVrqPrgR/8gHAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgqL7cBSYmJkK/MP3GG2/M2nfv3r3h7NVXX52191/91V+FcvV6Pf3pn/7pjxwbGxsLze+xxx4LnUPHHXfcEc4eOnQoa+8/+qM/CuUWFhbS1772tTXHH3nkkTQ4OFh5vejr2PGa17wmnH3LW96StffWrVsrZ4aHh9c9/sgjj6SRkZHK6/3Jn/xJ5Uy3zZs3h7O/8zu/k7X3xRdfHMr19Kz/d/LZ2dlUq9UqrzcxMRE6j46DBw+GsysrK1l79/f3F8scOXIkzc/PV14vd37PPvtsOPvwww9n7R29f9Tr9XWPX3755WlgYKDyenv27AmdR8fRo0fD2eeeey5r78g9pLe3d93jV199dRodHa28Xrvdrpzpdvfdd4ezkc+9bpHnm1JKrVbruP6cbzABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAovpyF7jpppvS4OBg5dw3v/nNrH3/4A/+IJz9yEc+krX3ww8/HMrNzMyse6zdblde6zOf+UzoHDpOO+20cHb//v1Ze7/44ouh3OLi4rrHjxw5kvr7+yuv99RTT4XOo+PUU08NZ2+++easvR988MHKmY3m19vbm/r6qt8KPvWpT1XOdLvlllvC2XPOOSdr7507d4Zy9Xp93eN//dd/HboGd+zYETqPjmazGc4ODAxk7b28vFw5s7S0tO7xffv2peHh4crrRWbebevWreHsRtfC8froRz8aym30Pn7rW9+aRkZGiq13vCJ7dtx3331Ze996662VM7Ozs+sev+KKK9LExETl9b7yla9UznSL3otSSqlWq2Xtffvtt4dy8/Pzx/XnfIMJAEBRCiYAAEUpmAAAFKVgAgBQlIIJAEBRCiYAAEUpmAAAFKVgAgBQlIIJAEBRCiYAAEUpmAAAFKVgAgBQlIIJAEBRCiYAAEX15S6wsLCQ2u125dwv/MIvZO1br9fD2auuuipr73/8x38M5WZnZ9cc+9d//dc0MDBQea2vf/3roXPo2LRpUzj73ve+N2vvHTt2hHILCwvrHr/gggvS0NBQ5fX27t0bOo+Onp74388effTRrL2feOKJypmVlZV1jx88eDANDw9XXu/WW2+tnOm20et5PK677rqsvefm5ormvvrVr4bWGx0dDeU6cq7Bk046KWvvSL7ZbK57/Otf/3rq7++vvN6BAwcqZ7o999xz4ezjjz+etfd3v/vdUK7Vaq17/ODBg6H74Bvf+MbQeXR861vfCmcj97FuV155ZVa+25133hl6P+beB9/whjeEs7nX/9atW0O5xcXF4/pzvsEEAKAoBRMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAiurLXWBycjINDQ1Vzk1MTGTtOz8/H86+8Y1vzNr7vPPOC+UajcaaYw899FDq7e2tvNb73//+0Dl09PXFX/qrrroqa+93vOMdoVy9Xk/XXXfdmuMnn3xyGh4errze3/7t34bOo2PPnj3h7L//+79n7d1sNotl6vV6Wlpaqrzee9/73sqZbkePHg1n//AP/zBr74985COhXKvVWvf40NBQqtVqlddbXl4OnUf3vifK4uJi5cxG1+Bpp52WBgYGKq+3e/fuypluW7ZsCWdvvfXWrL0nJydDuZWVlTQ9Pb3m+GWXXZbGxsYqr7fRNX28cq7h2267LWvvkq6//vrU399fOffbv/3bWfvmzP+GG27I2nv79u2h3PG+5r7BBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgqL5osN1up5RSWlhYCOVXVlaiW6eUUlpeXg5nO+ce1Wg0snLd+zebzdBaS0tLoVxHq9UKZ+fm5rL2rtfrWbnO/Do/5+fnQ+vNzs6Gch3Raz+l+Ove0dNT/e+GnT1Xzy/6PHKvg+jrVkL0+u/kVs8wek/JvRfl5HPuASnFruGN5he9n+d8DqSUdx/NnV/0M7CTWz3D6P0s93nk3Adzr/8cq+cXfT0WFxezziNn/rnzy33fvez+7aCpqal2Sskj8JiamjK/zPm5Bs3PDH9yH+Znhif6YX7lZriRWjtYgVutVpqenk7j4+OpVqtFlviZ0263U6PRSJOTkymlZH4Vdc+vp6fHNViR+eUzwzzml88M85hfvtUz3Ei4YAIAwHr8Ix8AAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICiFEwAAIpSMAEAKErBBACgKAUTAICi+qLBVquVpqen0/j4eKrVaiXP6adWu91OjUYjTU5OppSS+VXUPb+enh7XYEXml88M85hfvtUzhFercMGcnp5OO3fuLHkuPzOmpqZSSsn8gqamptKOHTtcg0Hml88M85hfvs4M4dUqXDDHx8dTSilt2bIl9Leow4cPR7dOKaX0ute9Lpz9vd/7vay9d+/eHcrNzs6m3/zN3/zh7FJK6TOf+UwaGRmpvNZ9990XOoeOb3/72+HsgQMHsvY+5ZRTQrlms5n279//w/l1fn7iE59IQ0NDldfLvQ7m5+fD2b//+7/P2vuhhx6qnFlZWUl33HHHmvn9zd/8TWh+x44dq5zptm/fvnD2G9/4RtbeUa1WKx05cmTNDD/0oQ+lwcHByus9+uijWecTvRellNJZZ52Vtfdb3vKWypl6vZ527ty5Zn5/+Zd/GboGv/nNb1bOdJuYmAhn2+121t5XX311KDc3N5euvfbaH/kcgVejcMHs/OeMnp6eE/I1fc6ekRtZt7Gxsax8938KGhkZCRXMyIdZt76+8Euf/Xr39vZm5Tvz6/wcGhpKw8PDldfJ+XBJKaX+/v5wNvf1y9m71PwWFxfD55BSSgMDA+Hsif5Pg6tnODg4GHpNc17HlFLodesYHR3N2jvn/bPeNRi5L+fOL+cabLVaWXtH7vvd/F8KeLXzf+AAAKAoBRMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAilIwAQAoqi93gR07dqTe3t7Kua1bt2btW6vVwtnDhw9n7f3000+HcnNzc2uO7d69O01MTFRea2RkJHQOHQ8++GA4u7S0lLV3vV4P5Vqt1rrHn3rqqTQ4OFh5vU9/+tOh8+g4cOBAOHvDDTdk7T08PFw502631z1++eWXp7GxscrrnXXWWZUz3W666aZw9hvf+EbW3keOHAnlNprh1q1bQ6/J9u3bQ+fREX0eKaX0xS9+MWvvHTt2VM7MzMyse/yiiy5Ko6OjldeLXLfdPvGJT4Szr33ta7P2/rmf+7lQbqMZwquNbzABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAovpyF/jgBz+YRkZGKuf+93//N2vf4eHhcPbZZ5/N2vuBBx4I5RYXF9ccGx0dTaOjo5XX6u/vD51DxwsvvBDOvvTSS1l7b968OZRrtVrrHv/Upz6VarVazimF/MZv/EY4u7S0lLX3xMRE5cxG83vta18bWq+3t7dyptvWrVvD2dz5LSwsZOVXe/rpp9Pg4GDlXL1ez9p3ZmYmnM2Zf0opfelLX6qc2WjuY2NjaWxsrPJ6N998c+VMt/3794ezV1xxRdbeZ599diiXe83AK8U3mAAAFKVgAgBQlIIJAEBRCiYAAEUpmAAAFKVgAgBQlIIJAEBRCiYAAEUpmAAAFKVgAgBQlIIJAEBRCiYAAEUpmAAAFKVgAgBQVF/uAr/yK7+SxsfHK+eeffbZrH3vuuuuE5JNKaWRkZFQrtVqrTk2NzeX+vqqvwx79uwJnUNHvV4PZ0dHR7P2js6v2Wyue7zdbqd2u115vZ6evL9f7d27N5wdHh7O2nv79u2VM81mM7344otrjh87dmzda/PlnHzyyZUz3e67775wdnFxMWvv6Lm32+300ksvrTnebDY3vD5/nH379oXOo+Pcc88NZ3PvIbfffntWvtuTTz4Zui80Go2sfd/2treFswcPHszau1arvaI5eKX5BhMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAilIwAQAoSsEEAKAoBRMAgKIUTAAAilIwAQAoqi93gVNPPTVNTExUzp100klZ+5511lnh7P79+7P2fu6550K5Vqu15ti+ffvS2NhY5bVuueWW0Dl0vPTSS+Fsb29v1t6jo6Oh3MrKyrrHzzjjjNA5nXLKKaHz6LjkkkvC2QMHDmTtvbCwUDmzsrKSHn300TXHo+/hQ4cOVc50y5nB8PBw1t4DAwOhXKvVWve986Y3vSmNjIxUXm/Tpk2h8+h43/veF85+4QtfyNp7165dlTNLS0vps5/97JrjY2NjofvCu9/97sqZbv/93/8dzt50001Ze3/4wx8O5RYXF7P2hVeKbzABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABACiqLxpst9sppZTq9XooPz8/H906pZTS4uJiONtsNrP2brVaWbnO7FJKaXZ2NrTWyspKKLf6XCK6zz8ieu6d162zf+dn9LnkzjDnGlxeXs7aO3Lunczq+UXfw41GI5TrWFpaCmdzrt+c/Or3cOdn9H62sLAQynXkvAa5e0dev05m9fzm5uZC55D7OZLzPsy9D0bvH6tnCK9WtXbwKj106FDauXNn6fP5mTA1NZVSSuYXNDU1lXbs2OEaDDK/fGaYx/zydWYIr1bhgtlqtdL09HQaHx9PtVqt9Hn9VGq326nRaKTJycmUUjK/irrn19PT4xqsyPzymWEe88u3eobwahUumAAAsB5//QEAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABAChKwQQAoCgFEwCAohRMAACKUjABACjq/wGS48aQAvddyAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN/nx))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i,0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "network = SimpleConvNet()\n",
    "\n",
    "# 랜덤 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 후의 가중치\n",
    "network.load_params('params.pkl')\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 전 필터는 무작위로 초기화되고 있어 흑백의 정도에 규칙성이 없음\n",
    "\n",
    "학습을 마친 필터는 규칙성있는 이미지가됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebb5e178611dee0187d78bd94b8f7077fa44d469125fdd14a4abea415e81f827"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
